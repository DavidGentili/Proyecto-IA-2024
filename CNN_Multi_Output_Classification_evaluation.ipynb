{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NBCERmUCqRQQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.model_selection as skl_model_selection\n",
        "import cv2\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, Conv2DTranspose, Conv2D, Input, BatchNormalization, MaxPooling2D, concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.saving import load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import Sequence\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"tawsifurrahman/tuberculosis-tb-chest-xray-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jtFV4wmqaEU",
        "outputId": "229ca5e9-b078-4768-e821-588fcf79319e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset/versions/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vamos a intentar obtener las imagenes, para eso primero debemos obtener la tabla\n",
        "\n",
        "base_path = \"TB_Chest_Radiography_Database\"\n",
        "tuberculosis_metadata = pd.read_excel(os.path.join(path, base_path,\"Tuberculosis.metadata.xlsx\"))\n",
        "normal_metadata = pd.read_excel(os.path.join(path, base_path,\"Normal.metadata.xlsx\"))\n",
        "\n",
        "\n",
        "dataset_tuberculosis_ids = tuberculosis_metadata[\"FILE NAME\"]\n",
        "dataset_normal_ids = normal_metadata[\"FILE NAME\"]\n",
        "\n",
        "\n",
        "dataset_tuberculosis_ids = np.array(dataset_tuberculosis_ids)\n",
        "dataset_normal_ids = np.array(dataset_normal_ids)\n",
        "\n",
        "dataset_tuberculosis_ids = \"Tuberculosis/\" + dataset_tuberculosis_ids\n",
        "dataset_normal_ids = \"Normal/\" + dataset_normal_ids\n",
        "\n",
        "val_dataset = np.concatenate((dataset_tuberculosis_ids[:50], dataset_normal_ids[:50]))\n",
        "val_target = np.concatenate((np.ones(50), np.zeros(50)))\n"
      ],
      "metadata": {
        "id": "Qi_Tahp1qawg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageMaskGenerator(Sequence):\n",
        "  def __init__(self, dataset_ids, dataset_label, dataset_path, batch_size=32, target_size=(224, 224), **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.dataset_ids = dataset_ids\n",
        "    self.dataset_label = dataset_label\n",
        "    self.dataset_path = dataset_path\n",
        "    self.batch_size = batch_size\n",
        "    self.target_size = target_size\n",
        "    self.indexes = np.arange(len(self.dataset_ids))\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(len(self.dataset_ids) / self.batch_size))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    batch_ids = self.dataset_ids[index * self.batch_size: (index + 1) * self.batch_size]\n",
        "    images = []\n",
        "    masks = []\n",
        "    labels = []\n",
        "    for id in batch_ids:\n",
        "      img_path = f\"{self.dataset_path}/{id}.png\"\n",
        "\n",
        "      img = load_img(path=img_path, color_mode=\"grayscale\", target_size=self.target_size)\n",
        "\n",
        "      img_array = img_to_array(img)\n",
        "\n",
        "      img_array /=255\n",
        "      mask_array = np.zeros_like(img_array)\n",
        "\n",
        "      label = self.get_classification_label(id)\n",
        "\n",
        "      images.append(img_array)\n",
        "      masks.append(mask_array)\n",
        "      labels.append(label)\n",
        "    return np.array(images), {\"segmentation\": np.array(masks), \"classification\": np.array(labels)}\n",
        "\n",
        "  def get_classification_label(self, id):\n",
        "    ind = np.where(self.dataset_ids == id)[0][0]\n",
        "    return self.dataset_label[ind]\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    np.random.shuffle(self.indexes)\n"
      ],
      "metadata": {
        "id": "XhJKT_78uUFq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "train_generator = ImageMaskGenerator(val_dataset, val_target, os.path.join(path, base_path), batch_size=batch_size)"
      ],
      "metadata": {
        "id": "igPzrk-Ku3UX"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"./model-it-04.h5\")\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={\n",
        "        \"segmentation\": \"binary_crossentropy\",\n",
        "        \"classification\": \"binary_crossentropy\",\n",
        "    },\n",
        "    metrics={\n",
        "        \"segmentation\": \"accuracy\",\n",
        "        \"classification\": \"accuracy\",\n",
        "    }\n",
        ")\n",
        "\n",
        "evaluation = model.evaluate(train_generator, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l3opmXRvT9P",
        "outputId": "cd2b8673-4184-493b-b65a-bd1e46edbd8e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 12s/step - classification_accuracy: 0.4868 - classification_loss: 3.7315 - loss: 5.1757 - segmentation_accuracy: 0.7944 - segmentation_loss: 1.4441\n",
            "{'classification_accuracy': 0.44999998807907104, 'classification_loss': 4.068774223327637, 'loss': 5.777108192443848, 'segmentation_accuracy': 0.7859352827072144, 'segmentation_loss': 1.708333969116211}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluation[\"classification_accuracy\"]\n",
        "print(f\"La presición del primer modelo para la clasificación es de {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6HlTF8R0lJl",
        "outputId": "3a84cef1-3d86-4b67-a44a-dd208cc3624f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La presición del modelo para la clasificación es de 0.44999998807907104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"./modelv2-01.keras\")\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={\n",
        "        \"segmentation\": \"binary_crossentropy\",\n",
        "        \"classification\": \"binary_crossentropy\",\n",
        "    },\n",
        "    metrics={\n",
        "        \"segmentation\": \"accuracy\",\n",
        "        \"classification\": \"accuracy\",\n",
        "    }\n",
        ")\n",
        "\n",
        "evaluation = model.evaluate(train_generator, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmQisJM-1Dkt",
        "outputId": "3f4c4e0f-4dc3-47d6-dacd-b4db65553495"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 74 variables whereas the saved optimizer has 146 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 12s/step - classification_accuracy: 0.1837 - classification_loss: 3.5403 - loss: 6.8384 - segmentation_accuracy: 0.5539 - segmentation_loss: 3.2981\n",
            "{'classification_accuracy': 0.4000000059604645, 'classification_loss': 2.5450263023376465, 'loss': 5.380401134490967, 'segmentation_accuracy': 0.6006415486335754, 'segmentation_loss': 2.8353734016418457}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluation[\"classification_accuracy\"]\n",
        "print(f\"La presición del primer modelo para la clasificación es de {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KRedP_-51AB",
        "outputId": "e7ce3eb6-8853-41a6-ac27-b7582fd156ba"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La presición del primer modelo para la clasificación es de 0.4000000059604645\n"
          ]
        }
      ]
    }
  ]
}